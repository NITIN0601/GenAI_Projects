# Financial RAG System - Project Structure

> **Morgan Stanley 10-Q/10-K Financial Document Analysis System**  
> LangChain-orchestrated RAG pipeline with advanced hybrid search capabilities

---

## ğŸ“ Project Structure

```
GENAI/
â”œâ”€â”€ ğŸ“„ main.py                          # Main CLI entry point
â”œâ”€â”€ ğŸ“„ requirements.txt                 # Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example                     # Configuration template
â”œâ”€â”€ ğŸ“„ README.md                        # Project overview
â”‚
â”œâ”€â”€ ğŸ“‚ config/                          # Configuration & Settings
â”‚   â”œâ”€â”€ settings.py                     # Centralized settings (VectorDB, LLM, Embeddings)
â”‚   â”œâ”€â”€ prompts.py                      # LangChain prompt templates
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ src/                             # Core Application Code
â”‚   â”œâ”€â”€ ğŸ“‚ extraction/                  # PDF Extraction System
â”‚   â”‚   â”œâ”€â”€ extractor.py                # Unified extractor with fallback
â”‚   â”‚   â”œâ”€â”€ enrichment.py               # âœ¨ Metadata enrichment (NEW)
â”‚   â”‚   â”œâ”€â”€ base.py                     # Base classes & interfaces
â”‚   â”‚   â”œâ”€â”€ strategy.py                 # Extraction strategy
â”‚   â”‚   â”œâ”€â”€ quality.py                  # Quality assessment
â”‚   â”‚   â”œâ”€â”€ cache.py                    # Extraction caching
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ backends/                # Extraction backends
â”‚   â”‚   â”‚   â”œâ”€â”€ docling_backend.py      # Docling (primary)
â”‚   â”‚   â”‚   â”œâ”€â”€ pymupdf_backend.py      # PyMuPDF (fallback)
â”‚   â”‚   â”‚   â”œâ”€â”€ pdfplumber_backend.py   # PDFPlumber (fallback)
â”‚   â”‚   â”‚   â””â”€â”€ camelot_backend.py      # Camelot (fallback)
â”‚   â”‚   â””â”€â”€ ğŸ“‚ formatters/              # Output formatters
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ embeddings/                  # Embedding Generation
â”‚   â”‚   â”œâ”€â”€ manager.py                  # Embedding manager (unified interface)
â”‚   â”‚   â”œâ”€â”€ multi_level.py              # Multi-level embeddings
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ chunking/                # Table chunking
â”‚   â”‚   â”‚   â””â”€â”€ table_chunker.py        # Smart table chunker
â”‚   â”‚   â””â”€â”€ ğŸ“‚ providers/               # Embedding providers
â”‚   â”‚       â”œâ”€â”€ local_provider.py       # HuggingFace (FREE)
â”‚   â”‚       â”œâ”€â”€ openai_provider.py      # OpenAI (PAID)
â”‚   â”‚       â””â”€â”€ custom_api_provider.py  # Custom API
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ vector_store/                # Vector Database Layer
â”‚   â”‚   â””â”€â”€ ğŸ“‚ stores/
â”‚   â”‚       â”œâ”€â”€ faiss_store.py          # FAISS (LangChain-compliant)
â”‚   â”‚       â”œâ”€â”€ chromadb_store.py       # ChromaDB (LangChain-compliant)
â”‚   â”‚       â””â”€â”€ redis_store.py          # Redis (LangChain-compliant)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ retrieval/                   # Retrieval & Search
â”‚   â”‚   â”œâ”€â”€ retrievers.py               # âœ¨ Advanced retrievers (NEW)
â”‚   â”‚   â”‚                               #    - BM25Retriever
â”‚   â”‚   â”‚                               #    - EnsembleRetriever (Hybrid)
â”‚   â”‚   â”œâ”€â”€ retriever.py                # Base retriever
â”‚   â”‚   â”œâ”€â”€ query_processor.py          # Query processing pipeline
â”‚   â”‚   â”œâ”€â”€ query_classifier.py         # Query type classification
â”‚   â”‚   â”œâ”€â”€ query_parser.py             # Query parsing
â”‚   â”‚   â””â”€â”€ reranker.py                 # Result reranking
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ llm/                         # LLM Integration
â”‚   â”‚   â”œâ”€â”€ manager.py                  # LLM manager
â”‚   â”‚   â””â”€â”€ ğŸ“‚ providers/
â”‚   â”‚       â”œâ”€â”€ ollama_provider.py      # Ollama (FREE)
â”‚   â”‚       â”œâ”€â”€ openai_provider.py      # OpenAI (PAID)
â”‚   â”‚       â””â”€â”€ custom_api_provider.py  # Custom API
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ rag/                         # RAG Pipeline
â”‚   â”‚   â”œâ”€â”€ pipeline.py                 # RAG orchestration
â”‚   â”‚   â”œâ”€â”€ context_builder.py          # Context assembly
â”‚   â”‚   â””â”€â”€ response_generator.py       # Response generation
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ cache/                       # Caching Layer
â”‚   â”‚   â””â”€â”€ ğŸ“‚ backends/
â”‚   â”‚       â””â”€â”€ redis_cache.py          # Redis cache
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/                      # Data Models
â”‚   â”‚   â”œâ”€â”€ schemas.py                  # Core schemas
â”‚   â”‚   â”œâ”€â”€ enhanced_schemas.py         # Enhanced financial schemas
â”‚   â”‚   â””â”€â”€ vectordb_schemas.py         # Vector DB schemas
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/                       # Utilities
â”‚       â”œâ”€â”€ logging_config.py           # Logging setup
â”‚       â”œâ”€â”€ metrics.py                  # Metrics collection
â”‚       â””â”€â”€ extraction_utils.py         # Extraction helpers
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                         # Utility Scripts
â”‚   â”œâ”€â”€ download_documents.py           # PDF downloader
â”‚   â”œâ”€â”€ ingest_pipeline.py              # Batch ingestion
â”‚   â”œâ”€â”€ verify_langchain.py             # LangChain verification
â”‚   â”œâ”€â”€ verify_enrichment.py            # Metadata enrichment test
â”‚   â””â”€â”€ migrate_vectordb.py             # Vector DB migration
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                           # Test Suite
â”‚   â”œâ”€â”€ test_extraction.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â””â”€â”€ test_rag.py
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                            # Documentation
â”‚   â””â”€â”€ (API docs, guides, etc.)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                            # Data Storage
â”‚   â”œâ”€â”€ processed/                      # Processed data
â”‚   â””â”€â”€ cache/                          # Cache files
â”‚
â”œâ”€â”€ ğŸ“‚ raw_data/                        # Raw PDF Files
â”‚   â””â”€â”€ (10-Q, 10-K PDFs)
â”‚
â”œâ”€â”€ ğŸ“‚ faiss_index/                     # FAISS Vector Store
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ metadata.pkl
â”‚
â”œâ”€â”€ ğŸ“‚ chroma_db/                       # ChromaDB Vector Store
â”‚
â”œâ”€â”€ ğŸ“‚ .logs/                           # Application Logs
â”‚
â””â”€â”€ ğŸ“‚ archive/                         # Legacy/Archived Code
```

---

##  Quick Start

### 1. Environment Setup

```bash
# Clone/Navigate to project
cd /Users/nitin/Desktop/Chatbot/Morgan/GENAI

# Activate virtual environment
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your settings
```

### 2. Configuration

Edit `.env` to configure:
- **Vector Database**: `VECTORDB_PROVIDER=faiss` (or `chromadb`, `redis`)
- **Embeddings**: `EMBEDDING_PROVIDER=local` (or `openai`, `custom`)
- **LLM**: `LLM_PROVIDER=ollama` (or `openai`, `custom`)

---

## ğŸ“‹ Available Commands

### Main Pipeline Commands

#### Download PDFs
```bash
# Download single quarter
python main.py download --yr 25 --m 03

# Download year range
python main.py download --yr 20-25

# Download all quarters for a year
python main.py download --yr 25
```

#### Extract Tables
```bash
# Extract from default directory (raw_data/)
python main.py extract

# Extract from custom directory
python main.py extract --source /path/to/pdfs

# Force re-extraction (ignore cache)
python main.py extract --force
```

#### Query System
```bash
# Single query
python main.py query "What was revenue in Q1 2025?"

# Interactive mode
python main.py interactive

# Advanced search (Hybrid/BM25/Vector)
python main.py search "Balance Sheet" --type hybrid --k 10
```

#### Complete Pipeline
```bash
# Download + Extract in one command
python main.py pipeline --yr 25 --m 03
```

#### System Utilities
```bash
# Show statistics
python main.py stats

# Clear cache
python main.py clear-cache

# Show help
python main.py --help
```

---

## ğŸ”§ Advanced Usage

### Custom Extraction

```python
from src.extraction.extractor import UnifiedExtractor

extractor = UnifiedExtractor(
    backends=['docling', 'pymupdf'],
    min_quality=70.0,
    enable_caching=True
)

result = extractor.extract('document.pdf')
print(f"Tables: {len(result.tables)}")
print(f"Quality: {result.quality_score}")
```

### Hybrid Search

```python
from src.retrieval.retrievers import get_retriever

# Get hybrid retriever (Vector + BM25)
retriever = get_retriever(search_type="hybrid", k=10)

# Search
results = retriever.invoke("Balance Sheet Q1 2025")
for doc in results:
    print(doc.page_content)
    print(doc.metadata)
```

### Metadata Enrichment

```python
from src.extraction.enrichment import get_metadata_enricher

enricher = get_metadata_enricher()

metadata = enricher.enrich_table_metadata(
    content="(in millions) | Revenue | $100 |",
    table_title="Consolidated Balance Sheet"
)

print(metadata['units'])           # 'millions'
print(metadata['statement_type'])  # 'balance_sheet'
print(metadata['currency'])        # 'USD'
```

---

## ğŸ§ª Testing & Verification

```bash
# Verify LangChain integration
python scripts/verify_langchain.py

# Verify metadata enrichment
python scripts/verify_enrichment.py

# Test extraction on sample PDF
python scripts/quick_test_extraction.py

# Run test suite
pytest tests/
```

---

## ğŸ“Š System Architecture

### Data Flow

```
PDF Documents
    â†“
[Extraction Layer]
    â”œâ”€ Docling (primary)
    â”œâ”€ PyMuPDF (fallback)
    â””â”€ PDFPlumber (fallback)
    â†“
[Metadata Enrichment]
    â”œâ”€ Units detection
    â”œâ”€ Currency detection
    â””â”€ Statement classification
    â†“
[Chunking Layer]
    â””â”€ Smart table chunking (overlap)
    â†“
[Embedding Generation]
    â”œâ”€ Local (HuggingFace)
    â”œâ”€ OpenAI
    â””â”€ Custom API
    â†“
[Vector Store]
    â”œâ”€ FAISS (fast)
    â”œâ”€ ChromaDB (persistent)
    â””â”€ Redis (distributed)
    â†“
[Retrieval Layer]
    â”œâ”€ Vector Search (semantic)
    â”œâ”€ BM25 Search (keyword)
    â””â”€ Hybrid Search (ensemble)
    â†“
[RAG Pipeline]
    â”œâ”€ Context assembly
    â”œâ”€ LLM generation
    â””â”€ Response formatting
    â†“
User Query Response
```

### Key Features

- [DONE] **Multi-backend Extraction**: Automatic fallback if primary fails
- [DONE] **Rich Metadata**: 30+ fields per table (units, currency, statement type, etc.)
- [DONE] **Smart Chunking**: Overlapping chunks preserve context
- [DONE] **Hybrid Search**: Combines semantic + keyword search
- [DONE] **LangChain Native**: Full LangChain integration
- [DONE] **Configurable**: All settings via `.env` and `settings.py`
- [DONE] **Caching**: Extraction and query caching for performance

---

## ğŸ”‘ Environment Variables

See `.env.example` for full list. Key variables:

```bash
# Vector Database
VECTORDB_PROVIDER=faiss

# Embeddings
EMBEDDING_PROVIDER=local
EMBEDDING_MODEL_LOCAL=sentence-transformers/all-MiniLM-L6-v2

# LLM
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434

# Search
SEARCH_TOP_K=5
HYBRID_SEARCH_ALPHA=0.5

# Paths
RAW_DATA_DIR=/path/to/pdfs
```

---

## ğŸ“š Additional Resources

- **Implementation Plan**: See `implementation_plan.md` in artifacts
- **Task Checklist**: See `task.md` in artifacts
- **Walkthrough**: See `walkthrough.md` in artifacts
- **README**: See `README.md` for project overview

---

## ğŸ†˜ Troubleshooting

### Import Errors
```bash
# Ensure virtual environment is activated
source .venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

### FAISS Segmentation Fault
```bash
# Set environment variable
export KMP_DUPLICATE_LIB_OK=TRUE
```

### Missing PDFs
```bash
# Download PDFs first
python main.py download --yr 25
```

---

**Last Updated**: 2025-11-30  
**Version**: 2.0 (LangChain Orchestrated)
