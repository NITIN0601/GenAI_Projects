# ============================================================================
# PROJECT SETTINGS
# ============================================================================
ENVIRONMENT=dev
DEBUG=True

# ============================================================================
# VECTOR DATABASE CONFIGURATION
# ============================================================================
# Options: faiss, chromadb, redis
VECTORDB_PROVIDER=faiss

# FAISS Settings
FAISS_PERSIST_DIR=/path/to/project/faiss_db
FAISS_INDEX_TYPE=flat

# ChromaDB Settings
CHROMA_PERSIST_DIR=/path/to/project/chroma_db
CHROMA_COLLECTION_NAME=financial_data

# Redis Vector Settings
REDIS_VECTOR_HOST=localhost
REDIS_VECTOR_PORT=6379
REDIS_VECTOR_INDEX=financial_tables_idx

# ============================================================================
# EMBEDDING CONFIGURATION
# ============================================================================
# Options: local, openai, custom
EMBEDDING_PROVIDER=local

# Local (Sentence Transformers)
EMBEDDING_MODEL_LOCAL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION_LOCAL=384

# OpenAI
EMBEDDING_MODEL_OPENAI=text-embedding-3-small
EMBEDDING_DIMENSION_OPENAI=1536
OPENAI_API_KEY=sk-...

# Custom API
EB_URL=https://api.example.com/embed
EB_MODEL=custom-model
UNIQUE_ID=user-id
BEARER_TOKEN=token

# ============================================================================
# LLM CONFIGURATION
# ============================================================================
# Options: ollama, openai, custom
LLM_PROVIDER=ollama

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# OpenAI
OPENAI_MODEL=gpt-4

# Custom API
LLM_URL=https://api.example.com/chat
LLM_MODEL_CUSTOM=custom-chat-model
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2000

# ============================================================================
# SEARCH & RETRIEVAL CONFIGURATION
# ============================================================================
SEARCH_TOP_K=5
SEARCH_FETCH_K=20
HYBRID_SEARCH_ALPHA=0.5
BM25_K1=1.5
BM25_B=0.75
SIMILARITY_THRESHOLD=0.7

# ============================================================================
# EXTRACTION CONFIGURATION
# ============================================================================
# Options: docling, pymupdf, pdfplumber, camelot
EXTRACTION_BACKEND=docling
EXTRACTION_MIN_QUALITY=60.0
EXTRACTION_CACHE_ENABLED=True
EXTRACTION_CACHE_TTL_HOURS=168

# PDF Processing
HANDLE_TWO_COLUMN=True
EXTRACT_TABLES=True
PDF_MAX_SIZE_MB=500

# ============================================================================
# DATA & PATHS
# ============================================================================
RAW_DATA_DIR=/path/to/project/raw_data
CHUNK_SIZE=10
CHUNK_OVERLAP=3

# ============================================================================
# REDIS CACHE (GENERAL)
# ============================================================================
REDIS_ENABLED=False
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
CACHE_TTL=86400

# ============================================================================
# FEATURE FLAGS
# ============================================================================
ENABLE_CHUNKING=True
ENABLE_DEDUPLICATION=True
ENABLE_PROGRESS_BARS=True

# ============================================================================
# SCHEDULER SETTINGS
# ============================================================================
# Enable automatic quarterly filing downloads
SCHEDULER_ENABLED=False
SCHEDULER_AUTO_EXTRACT=True
SCHEDULER_LOOKAHEAD_DAYS=180
SCHEDULER_CHECK_INTERVAL_HOURS=24

# ============================================================================
# TABLE EXPORT SETTINGS
# ============================================================================
# Directory for consolidated table exports
OUTPUT_DIR=outputs/tables
# Export both CSV and Excel formats
EXPORT_BOTH_FORMATS=True
# Similarity threshold for table title matching (0.0-1.0)
TABLE_SIMILARITY_THRESHOLD=0.85

# ============================================================================
# RAG OUTPUT SETTINGS
# ============================================================================
# Save retrieved tables from RAG queries to CSV/Excel
SAVE_RAG_TABLES=true
# Save text responses to log files
SAVE_RAG_RESPONSES=true
# Directory for RAG query outputs (tables + logs)
RAG_OUTPUT_DIR=output/rag_queries

# ============================================================================
# LANGSMITH TRACING (Observability)
# ============================================================================
# Enable LangSmith tracing for observability
LANGSMITH_TRACING=False
# Your LangSmith API key (get from https://smith.langchain.com)
LANGSMITH_API_KEY=lsv2_pt_...
# Project name in LangSmith dashboard
LANGSMITH_PROJECT=genai-rag
# LangSmith endpoint (default: https://api.smith.langchain.com)
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
# Trace sampling rate (1.0 = all, 0.1 = 10%)
LANGSMITH_SAMPLE_RATE=1.0
